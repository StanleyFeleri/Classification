# -*- coding: utf-8 -*-
"""ProjectAnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/123iGCxkvJOt4iXA0RKc8dDcSImRinzpx
"""

import pandas as pd
import tensorflow as tf
import numpy as np
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.model_selection import train_test_split

# Load Dataset
def load_dataset():
  dataset=pd.read_csv('classification.csv')
  return dataset

dataset = load_dataset()

for index,i in enumerate(dataset['class']):
  if i == 'p':
    dataset['class'][index] = 0
  else:
    dataset['class'][index] = 1

for index,i in enumerate(dataset['cap-shape']):
  if i == 'b':
   dataset['cap-shape'][index] = 1
  elif i == 'c':
   dataset['cap-shape'][index] = 2
  elif i == 'x':
   dataset['cap-shape'][index] = 3
  elif i == 'f':
   dataset['cap-shape'][index] = 4
  elif i == 'k':
   dataset['cap-shape'][index] = 5
  elif i == 's':
   dataset['cap-shape'][index] = 6

for index,i in enumerate(dataset['odor']):
  if i == 'a':
    dataset['odor'][index] = 1
  elif i == 'l':
    dataset['odor'][index] = 2
  elif i == 'c':
    dataset['odor'][index] = 3
  elif i == 'y':
   dataset['odor'][index] = 4
  elif i == 'f':
    dataset['odor'][index] = 5
  elif i == 'm':
    dataset['odor'][index] = 6
  elif i == 'n':
    dataset['odor'][index] = 7
  elif i == 'p':
    dataset['odor'][index] = 8
  elif i == 's':
    dataset['odor'][index] = 9

for index,i in enumerate(dataset['habitat']):
  if i == 'g':
    dataset['habitat'][index] = 1
  elif i == 'l':
    dataset['habitat'][index] = 2
  elif i == 'm':
    dataset['habitat'][index] = 3
  elif i == 'p':
    dataset['habitat'][index] = 4
  elif i == 'u':
    dataset['habitat'][index] = 5
  elif i == 'w':
    dataset['habitat'][index] = 6
  elif i == 'd':
    dataset['habitat'][index] = 7

x = dataset[['cap-shape','cap-color','odor','stalk-color-above-ring','stalk-color-below-ring','veil-color','ring-number','habitat']]
y = dataset[['class']]

dataset

# VARIABEL PEMBANTU MODEL
#MODEL
input_tensor = tf.placeholder(tf.float32, name='input')
label_tensor = tf.placeholder(tf.float32, name='label')

parameters = {
    'W1' : tf.Variable(
        tf.random.normal([4, 64]),
        dtype = tf.float32,
        name = 'W1'
    ),
    'B1' : tf.Variable(
        tf.random.normal([1, 64]),
        dtype = tf.float32,
        name = 'B1'
    ),

    'W2' : tf.Variable(
        tf.random.normal([64, 64]),
        dtype = tf.float32,
        name = 'W2'
    ),
    'B2' : tf.Variable(
        tf.random.normal([1, 64]),
        dtype = tf.float32,
        name = 'B2'
    ),

    'W3' : tf.Variable(
        tf.random.normal([64, 2]),
        dtype = tf.float32,
        name = 'W3'
    ),
    'B3' : tf.Variable(
        tf.random.normal([1, 2]),
        dtype = tf.float32,
        name = 'B3'
    )
}

# PREPROCESSING Dataset
scaler = MinMaxScaler().fit(x)
x = scaler.transform(x)

from sklearn.decomposition import PCA
pca = PCA(n_components=4)
x = pca.fit_transform(x)

train = np.int(len(x)*0.7) 
test = np.int(len(x)*0.2)+train
eval = np.int(len(x) *0.1)+test

x_train = x[:train]
x_test = x[train:test]
x_eval = x[test:eval]
y_train= y[:train]
y_test = y[train:test]
y_eval = y[test:eval]

# Function Forward PASS
def forward_pass(x):
  wx_b1=tf.matmul(x,parameters['W1']) + parameters['B1']
  y1= tf.nn.sigmoid(wx_b1)

  wx_b2=tf.matmul(y1,parameters['W2']) + parameters['B2']
  y2=tf.nn.sigmoid(wx_b2)
  
  wx_b3=tf.matmul(y2,parameters['W3']) + parameters['B3']
  y3=tf.nn.sigmoid(wx_b3)
  
  return y3

epoch=2500
alpha=0.01

saver = tf.train.Saver()

with tf.Session() as sess:
  y=forward_pass(input_tensor)

  # Mean Squared Error(MSE) Function
  
  error=tf.reduce_mean(0.5*(label_tensor-y)**2)
  optimizer=tf.train.GradientDescentOptimizer(alpha)
  train=optimizer.minimize(error)

  sess.run(tf.global_variables_initializer())
  CE=1000
  for i in range(epoch+1):
    sess.run(
        train,
        feed_dict={
            input_tensor:x_train,
            label_tensor:y_train})
    

    if i % 25 == 0:
      current_error=sess.run(
          error,
          feed_dict={
              input_tensor: x_train,
              label_tensor:y_train
          })
      # true_prediction=tf.equal(tf.argmax(y,axis=1),tf.argmax(label_tensor,axis=1))
      # accuracy= tf.reduce_mean(tf.cast(true_prediction ,tf.float32))
      # accuracy=sess.run(
      #     accuracy,
      #     feed_dict={
      #       input_tensor:x_train,
      #       label_tensor:y_train    
          
      #     })
      print(f'Epoch:{i} | Error: {current_error: .4f}')
    
    if i % 125 == 0:
      current_error=sess.run(
          error,
          feed_dict={
              input_tensor: x_train,
              label_tensor:y_train
          })
     
      if(CE>current_error):
        CE=current_error
        saver.save(sess, './Classification-Model.ckpt')
     
      print(f'Error: {current_error: .4f}')
  true_prediction=tf.equal(tf.argmax(y,axis=1),tf.argmax(label_tensor,axis=1))
  accuracy= tf.reduce_mean(tf.cast(true_prediction ,tf.float32))
  accuracy=sess.run(
      accuracy,
      feed_dict={
        input_tensor:x_eval,
        label_tensor:y_eval   
          
       })
  print(f'Accuracy:{accuracy*100}%')